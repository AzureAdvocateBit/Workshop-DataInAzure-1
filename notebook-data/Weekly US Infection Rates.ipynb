{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Introduction to Data Storage in Azure \n\nWe'll be using a some existing data to track weekly confirmed cases in the United States\n[Be sure to follow the instructions in the repository](https://github.com/paladique/Workshop-DataInAzure/blob/master/README.md) before continuing here\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!{sys.executable} -m pip install pyarrow\n!{sys.executable} -m pip install pandas\n",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting pyarrow\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/ec/82aaab43393bbf3321caff905506cc4045e4c4a503845f749798370bc4c2/pyarrow-0.17.1-cp35-cp35m-manylinux2014_x86_64.whl (63.7MB)\n\u001b[K     |████████████████████████████████| 63.7MB 7.1kB/s eta 0:00:01    |▉                               | 1.6MB 2.1MB/s eta 0:00:30     |█▊                              | 3.4MB 2.1MB/s eta 0:00:29     |████████▎                       | 16.4MB 3.2MB/s eta 0:00:15     |███████████████████▋            | 39.1MB 4.2MB/s eta 0:00:06MB/s eta 0:00:06MB/s eta 0:00:06████████████████▎         | 44.4MB 5.8MB/s eta 0:00:04     |███████████████████████▍        | 46.5MB 485kB/s eta 0:00:36     |███████████████████████▌        | 46.7MB 485kB/s eta 0:00:36:00:35��▊       | 49.3MB 485kB/s eta 0:00:30�████████████▌      | 50.7MB 449kB/s eta 0:00:29�█████████████      | 51.9MB 449kB/s eta 0:00:27�██████████████████████████▏    | 54.0MB 449kB/s eta 0:00:22MB/s eta 0:00:03MB/s eta 0:00:03��████▏   | 56.2MB 3.3MB/s eta 0:00:03��████████████████████▊   | 57.2MB 3.3MB/s eta 0:00:02�█████████████████████▏ | 60.0MB 3.2MB/s eta 0:00:02��██████████████████████████▊ | 61.1MB 3.2MB/s eta 0:00:01ta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy>=1.14 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from pyarrow) (1.17.3)\nInstalling collected packages: pyarrow\nSuccessfully installed pyarrow-0.17.1\n\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\nRequirement already satisfied: pandas in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (0.19.2)\nRequirement already satisfied: python-dateutil>=2 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from pandas) (2.8.1)\nRequirement already satisfied: pytz>=2011k in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from pandas) (2016.6.1)\nRequirement already satisfied: numpy>=1.7.0 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from pandas) (1.17.3)\nRequirement already satisfied: six>=1.5 in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from python-dateutil>=2->pandas) (1.11.0)\n\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\nYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's grab the COVID data from the [Open Datasets Catalog](https://azure.microsoft.com/en-us/services/open-datasets/catalog/bing-covid-19-data/)\n_**Be sure to download the json file and upload it to your blob container if you haven't already!**_"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Install important packages\nimport os, sys\nimport pyarrow.parquet as pq\nimport pandas as pd\nimport pyodbc\nimport numpy as np\n# %matplotlib inline\n# import matplotlib.pyplot as plt\n\n\nfrom datetime import datetime\nfrom dateutil import parser\nfrom dateutil.relativedelta import relativedelta\n\n#Load csv Data\ndf_covid = pd.read_csv(\"bing_covid-19_data.csv\")",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "us_cases = df_covid.query('iso2 == \"US\"')\nus_cases[['confirmed','updated']].groupby(pd.Grouper(key='updated',freq='W')).sum()\n",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 115,
          "data": {
            "text/plain": "             confirmed\nupdated               \n2020-01-05   4031065.0\n2020-01-12   5183035.0\n2020-01-19         NaN\n2020-01-26        23.0\n2020-02-02        63.0\n2020-02-09   9440153.0\n2020-02-16        59.0\n2020-02-23       205.0\n2020-03-01       301.0\n2020-03-08   9671943.0\n2020-03-15     18169.0\n2020-03-22    293575.0\n2020-03-29   1760757.0\n2020-04-05   5567710.0\n2020-04-12   5352955.0\n2020-04-19  14461869.0\n2020-04-26  18783079.0\n2020-05-03  12663285.0\n2020-05-10   9947333.0\n2020-05-17  20706861.0\n2020-05-24  31698656.0\n2020-05-31  34647101.0\n2020-06-07  10051879.0\n2020-06-14  11823329.0\n2020-06-21   2686091.0\n2020-06-28         NaN\n2020-07-05   4855639.0\n2020-07-12   5454482.0\n2020-07-19         NaN\n2020-07-26         NaN\n2020-08-02        12.0\n2020-08-09  10620478.0\n2020-08-16         NaN\n2020-08-23         NaN\n2020-08-30         NaN\n2020-09-06  10858361.0\n2020-09-13         NaN\n2020-09-20         NaN\n2020-09-27         NaN\n2020-10-04   1532998.0\n2020-10-11   9432144.0\n2020-10-18         NaN\n2020-10-25         NaN\n2020-11-01         NaN\n2020-11-08  11312149.0\n2020-11-15         NaN\n2020-11-22         NaN\n2020-11-29         NaN\n2020-12-06  11503728.0",
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>confirmed</th>\n    </tr>\n    <tr>\n      <th>updated</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-01-05</th>\n      <td>4031065.0</td>\n    </tr>\n    <tr>\n      <th>2020-01-12</th>\n      <td>5183035.0</td>\n    </tr>\n    <tr>\n      <th>2020-01-19</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-01-26</th>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>2020-02-02</th>\n      <td>63.0</td>\n    </tr>\n    <tr>\n      <th>2020-02-09</th>\n      <td>9440153.0</td>\n    </tr>\n    <tr>\n      <th>2020-02-16</th>\n      <td>59.0</td>\n    </tr>\n    <tr>\n      <th>2020-02-23</th>\n      <td>205.0</td>\n    </tr>\n    <tr>\n      <th>2020-03-01</th>\n      <td>301.0</td>\n    </tr>\n    <tr>\n      <th>2020-03-08</th>\n      <td>9671943.0</td>\n    </tr>\n    <tr>\n      <th>2020-03-15</th>\n      <td>18169.0</td>\n    </tr>\n    <tr>\n      <th>2020-03-22</th>\n      <td>293575.0</td>\n    </tr>\n    <tr>\n      <th>2020-03-29</th>\n      <td>1760757.0</td>\n    </tr>\n    <tr>\n      <th>2020-04-05</th>\n      <td>5567710.0</td>\n    </tr>\n    <tr>\n      <th>2020-04-12</th>\n      <td>5352955.0</td>\n    </tr>\n    <tr>\n      <th>2020-04-19</th>\n      <td>14461869.0</td>\n    </tr>\n    <tr>\n      <th>2020-04-26</th>\n      <td>18783079.0</td>\n    </tr>\n    <tr>\n      <th>2020-05-03</th>\n      <td>12663285.0</td>\n    </tr>\n    <tr>\n      <th>2020-05-10</th>\n      <td>9947333.0</td>\n    </tr>\n    <tr>\n      <th>2020-05-17</th>\n      <td>20706861.0</td>\n    </tr>\n    <tr>\n      <th>2020-05-24</th>\n      <td>31698656.0</td>\n    </tr>\n    <tr>\n      <th>2020-05-31</th>\n      <td>34647101.0</td>\n    </tr>\n    <tr>\n      <th>2020-06-07</th>\n      <td>10051879.0</td>\n    </tr>\n    <tr>\n      <th>2020-06-14</th>\n      <td>11823329.0</td>\n    </tr>\n    <tr>\n      <th>2020-06-21</th>\n      <td>2686091.0</td>\n    </tr>\n    <tr>\n      <th>2020-06-28</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-07-05</th>\n      <td>4855639.0</td>\n    </tr>\n    <tr>\n      <th>2020-07-12</th>\n      <td>5454482.0</td>\n    </tr>\n    <tr>\n      <th>2020-07-19</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-07-26</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-08-02</th>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>2020-08-09</th>\n      <td>10620478.0</td>\n    </tr>\n    <tr>\n      <th>2020-08-16</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-08-23</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-08-30</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-09-06</th>\n      <td>10858361.0</td>\n    </tr>\n    <tr>\n      <th>2020-09-13</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-09-20</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-09-27</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-10-04</th>\n      <td>1532998.0</td>\n    </tr>\n    <tr>\n      <th>2020-10-11</th>\n      <td>9432144.0</td>\n    </tr>\n    <tr>\n      <th>2020-10-18</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-10-25</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-11-01</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-11-08</th>\n      <td>11312149.0</td>\n    </tr>\n    <tr>\n      <th>2020-11-15</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-11-22</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-11-29</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2020-12-06</th>\n      <td>11503728.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Querying from the Database\n\nNow that the data is in Azure SQL, lets query it. Be sure to add and update `myconfig.cfg` with the following:\n\n  ```python\n[my_db]\nserver: [your Azure SQL server name]\ndatabase: [your Azure SQL database name]\nusername: [your Azure SQL username]\npassword: [your Azure SQL password]\n  ```\n  \n  **Note: The file will contain critical information. Avoid setting your notebook public until they are removed.**"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## What's Happening?! Using Azure Data Factory\n\nLooks like this data has some parsing and formatting issues! Let's clean it up - we'll grab the JSON version of this file and put it in Azure SQL\n\nHere's a preview of the structure:\n\n```json\n{\n  \"id\": 338995,\n  \"updated\": \"2020-01-21\",\n  \"confirmed\": 262,\n  \"deaths\": 0,\n  \"country_region\": \"Worldwide\",\n  \"load_time\": \"2020-06-16 00:05:27\"\n}\n```\nHow do we convert this semi-structed data into relational data? Let's use the Azure Data Factory to achieve this. \n\n1. From the Azure Portal, Open you Data Factory and select **Author and Monitor**, which will open a new tab.\n2. In the Data Factory home page, select **Copy Data** to setup the manual task \n3. After clicking Next on Properties, let's create our data connections. \n\n    3a. Select **+ Create New Connection**\n    \n    3b. Search for Blob Storage, select **Azure Blob Storage** > **Next**\n    \n    3c. Select your Azure Subscirption and your Storage Account Name, select **Create**\n    \n    3d. Repeat this process for Azure SQL Database and use SQL authentication \n    \n    Optional: Test your connection\n\n4. Select Azure Blob Storage connection as the source > **Next** \n5. Select **Browse** on the right hand side, select your container and click **Choose** on `bing_covid-19_data.json` > **Next** \n6. Confirm the file format is json, select it if not and click **Next**\n4. Select Azure SQL connection as the destination target > **Next** \n4. Select the CovidData databsase as the destination target > **Next** \n5. We're only interested in the `id, updated, and confirmed` columns, deleting the other rows is optional > click **Next** until you reach the `Deployment complete` window\n7. Loading this data will take a few minutes.\n\n### To much clicking? \nYou can build data piplines in Data Factory with the command line"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from configparser import ConfigParser\nparser = ConfigParser()\n_ = parser.read('myconfig.cfg')\n\n\nserver = parser.get('my_db', 'server')\ndatabase = parser.get('my_db', 'database')\nusername = parser.get('my_db', 'username')\npassword = parser.get('my_db', 'password')\ncnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)",
      "execution_count": 116,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "query = \"SELECT * FROM [dbo].[CovidData] WHERE country_region='United States'\" \ndf_covid_us_sql = pd.read_sql(query, cnxn)\ndf_covid_us_sql['country_region'] = f['country_region'].str.strip()\ndf_covid_us_sql.head(10)\n\ndf_covid_us_sql[['confirmed','updated']].groupby(pd.Grouper(key='updated',freq='W')).sum()",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 117,
          "data": {
            "text/plain": "            confirmed\nupdated              \n2020-01-26         23\n2020-02-02         79\n2020-02-09         94\n2020-02-16         97\n2020-02-23        205\n2020-03-01        402\n2020-03-08       3528\n2020-03-15      27931\n2020-03-22     293590\n2020-03-29    1760926\n2020-04-05    5224485\n2020-04-12   10034648\n2020-04-19   14461820\n2020-04-26   18783118\n2020-05-03   23067118\n2020-05-10   25577309\n2020-05-17   28546784\n2020-05-24   31698223\n2020-05-31   34646500\n2020-06-07   37292862\n2020-06-14   37767903",
            "text/html": "<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>confirmed</th>\n    </tr>\n    <tr>\n      <th>updated</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2020-01-26</th>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>2020-02-02</th>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>2020-02-09</th>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>2020-02-16</th>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>2020-02-23</th>\n      <td>205</td>\n    </tr>\n    <tr>\n      <th>2020-03-01</th>\n      <td>402</td>\n    </tr>\n    <tr>\n      <th>2020-03-08</th>\n      <td>3528</td>\n    </tr>\n    <tr>\n      <th>2020-03-15</th>\n      <td>27931</td>\n    </tr>\n    <tr>\n      <th>2020-03-22</th>\n      <td>293590</td>\n    </tr>\n    <tr>\n      <th>2020-03-29</th>\n      <td>1760926</td>\n    </tr>\n    <tr>\n      <th>2020-04-05</th>\n      <td>5224485</td>\n    </tr>\n    <tr>\n      <th>2020-04-12</th>\n      <td>10034648</td>\n    </tr>\n    <tr>\n      <th>2020-04-19</th>\n      <td>14461820</td>\n    </tr>\n    <tr>\n      <th>2020-04-26</th>\n      <td>18783118</td>\n    </tr>\n    <tr>\n      <th>2020-05-03</th>\n      <td>23067118</td>\n    </tr>\n    <tr>\n      <th>2020-05-10</th>\n      <td>25577309</td>\n    </tr>\n    <tr>\n      <th>2020-05-17</th>\n      <td>28546784</td>\n    </tr>\n    <tr>\n      <th>2020-05-24</th>\n      <td>31698223</td>\n    </tr>\n    <tr>\n      <th>2020-05-31</th>\n      <td>34646500</td>\n    </tr>\n    <tr>\n      <th>2020-06-07</th>\n      <td>37292862</td>\n    </tr>\n    <tr>\n      <th>2020-06-14</th>\n      <td>37767903</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "When compared to the following [Bing Visualization](https://bing.com/covid/local/unitedstates), we can see that we're _very_ off, but in better shape than the original query."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "name": "LoadAzureBlobParquet",
    "notebookId": 576599826755691,
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "file_extension": ".py",
      "version": "3.5.4",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}